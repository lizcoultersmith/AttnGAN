{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Super-Piano-2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lizcoultersmith/AttnGAN/blob/master/Super_Piano_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avfslsXnDS4j"
      },
      "source": [
        "#Super Piano 2\n",
        "\n",
        "MAKE YOUR OWN SOTA PIANO MUSIC AI MODEL IN UNDER 4 HOURS !!! :)\n",
        "\n",
        "Based on Yuankui Lee's repo and code https://github.com/djosix/Performance-RNN-PyTorch\n",
        "\n",
        "MAESTRO Dataset is courtesy of Google Magenta Team and it is distributed under Attribution-NonCommercial-ShareAlike 4.0 International license.\n",
        "\n",
        "So keep this in mind and respect everyone's copyright, please :)\n",
        "\n",
        "Huge thanks go out to all people who shared these amazing code contributions and made this Colab notebook possible :) Thank you so much, guys!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHWiJvW4vmGM"
      },
      "source": [
        "## Setup the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2Zz7WiBy9qC",
        "cellView": "form"
      },
      "source": [
        "#@title Install all dependencies and requrements\n",
        "print('3..2..1..lets do it')\n",
        "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install numpy\n",
        "%tensorflow_version 1.x\n",
        "!pip install tensorflow-gpu==1.15.3\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  \n",
        "import tensorflow as tf\n",
        "!pip install tensorboard\n",
        "!pip install progress\n",
        "!pip install pretty-midi\n",
        "!pip install pypianoroll\n",
        "!pip install matplotlib\n",
        "!pip install mir_eval\n",
        "!pip install librosa\n",
        "!pip install pyFluidSynth\n",
        "!apt install fluidsynth #Pip does not work for some reason. Only apt works\n",
        "!pip install midi2audio\n",
        "!git clone https://github.com/asigalov61/Performance-RNN-PyTorch\n",
        "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 /content/font.sf2\n",
        "from midi2audio import FluidSynth\n",
        "from google.colab import output\n",
        "from IPython.display import display, Javascript, HTML, Audio\n",
        "!nvidia-smi\n",
        "print('Success :) Everything is installed and should work fine :) Enjoy!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv25m6-Xuzlu"
      },
      "source": [
        "### Download and Unzip training MIDIs DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvcch3KePuCq",
        "cellView": "form"
      },
      "source": [
        "#@title (Best Choice/Works best stand-alone) Super Piano 2 Performance DataSet 320 MIDIs \n",
        "%cd /content/Performance-RNN-PyTorch/dataset/midi\n",
        "!wget 'https://github.com/asigalov61/AlexMIDIDataSet/raw/master/Super-Piano-2-Performance-DataSet-CC-BY-NC-SA.zip'\n",
        "!unzip -j 'Super-Piano-2-Performance-DataSet-CC-BY-NC-SA.zip'\n",
        "!rm 'Super-Piano-2-Performance-DataSet-CC-BY-NC-SA.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLOHEIgemfRD"
      },
      "source": [
        "###(Optional) Download the pre-trained model to generate music without training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMC1hNL6mukM",
        "cellView": "form"
      },
      "source": [
        "#@title Super Piano 2 Pre-Trained Performance Model (floss=1.05 - 4k training steps)\n",
        "%cd /content/Performance-RNN-PyTorch/save\n",
        "!wget 'https://superpiano.s3-us-west-1.amazonaws.com/myModel.sess'\n",
        "%cd /content/Performance-RNN-PyTorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj4PwQitvSVa"
      },
      "source": [
        "### Prepare and pre-process your MIDI DataSet for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1q2Xa900PuZ",
        "cellView": "form"
      },
      "source": [
        "#@title This may take a while, especially on the large DataSets, so please be patient\n",
        "number_of_parallel_threads = 64 #@param {type:\"slider\", min:1, max:64, step:1}\n",
        "%cd /content/Performance-RNN-PyTorch\n",
        "!python3 preprocess.py '/content/Performance-RNN-PyTorch/dataset/midi' '/content/Performance-RNN-PyTorch/dataset/processed' $number_of_parallel_threads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhnT38z_yuxp"
      },
      "source": [
        "### (Optional) Activate Tensorboard to monitor the progress of the model during training. You can also activate this cell at any other time to view logs/records of all training runs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGLZ_Gh4v63C",
        "cellView": "form"
      },
      "source": [
        "#@title Tensorboard Graphs and Stats\n",
        "# Load the TensorBoard notebook extension\n",
        "%reload_ext tensorboard\n",
        "import tensorflow as tf\n",
        "import datetime, os\n",
        "%tensorboard --logdir /content/Performance-RNN-PyTorch/runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLQcmGNdzfZi"
      },
      "source": [
        "###Train your model quickly here :) \n",
        "\n",
        "WARNING: Created/resulting Model may produce (partially) plagiarized (overfitted) output. Excercise care and respect the copyright, please :) NOTE: You can manipulate provided variables below to further influence/improve generated output. Only the first batch is downloaded and plotted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1l-9hW92vJX",
        "cellView": "form"
      },
      "source": [
        "#@title Main Training Loop\n",
        "\n",
        "number_of_batches = 384 #@param {type:\"slider\", min:1, max:512, step:1}\n",
        "window_size = 256 #@param {type:\"slider\", min:0, max:512, step:8}\n",
        "stride_size = 30 #@param {type:\"slider\", min:1, max:30, step:1}\n",
        "hidden_dimension_size = 1024 #@param {type:\"number\"}\n",
        "learning_rate = 0.001 #@param {type:\"number\"}\n",
        "control_ratio =  0.9#@param {type:\"number\"}\n",
        "teacher_forcing_ratio = 0.9 #@param {type:\"number\"}\n",
        "save_model_every = 10\n",
        "\n",
        "\n",
        "%cd /content/Performance-RNN-PyTorch\n",
        "!python3 train.py -s save/myModel.sess -d '/content/Performance-RNN-PyTorch/dataset/processed' -b $number_of_batches -w $window_size -c $control_ratio -T $teacher_forcing_ratio -t -L -p hidden_dim=$hidden_dimension_size -l $learning_rate -S $stride_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WSwGrMs2qNe"
      },
      "source": [
        "###Generate, Plot, Graph, Save, Download, and Render the resulting output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nQKPp51If-V"
      },
      "source": [
        "NOTES: Control option -c takes commands or a processed .data file path.\n",
        "E.g., \"PITCH_HISTOGRAM;NOTE_DENSITY\" like -c \"2,0,1,1,0,1,0,1,1,0,0,1;4\", or \";3\" which gives all pitches the same probability or a /path/to/processed/midi/file.data\" to use the specific control sequence from the given processed data file. Option -S stands for Stochastic Beam Search Option"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u0hx2NyoGn5"
      },
      "source": [
        "A sample on C Major Scale \n",
        "control option: -c '1,0,1,0,1,1,0,1,0,1,0,1;4'\n",
        "\n",
        "A sample on C Minor Scale \n",
        "control option: -c '1,0,1,1,0,1,0,1,1,0,0,1;4'\n",
        "\n",
        "A sample on C Major Pentatonic Scale \n",
        "control option: -c '5,0,4,0,4,1,0,5,0,4,0,1;3'\n",
        "\n",
        "A sample on C Minor Pentatonic Scale \n",
        "control option: -c '5,0,1,4,0,4,0,5,1,0,4,0;3'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnA3aoTE8SjZ",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "number_of_tokens_to_generate = 4096 #@param {type:\"slider\", min:128, max:16384, step:128}\n",
        "model_temperature = 0.8 #@param {type:\"slider\", min:0, max:5, step:0.1}\n",
        "number_of_batches_and_files_to_generate = 1 #@param {type:\"slider\", min:1, max:32, step:1}\n",
        "full_model_path_and_file_name = \"/content/Performance-RNN-PyTorch/save/myModel.sess\" #@param {type:\"string\"}\n",
        "greedy_ratio = \"0\" #@param {type:\"string\"}\n",
        "generation_control_seed = \"\" #@param {type:\"string\"}\n",
        "extra_flags = \"\" #@param {type:\"string\"}\n",
        "\n",
        "%cd /content/Performance-RNN-PyTorch\n",
        "\n",
        "!python3 generate.py -l $number_of_tokens_to_generate -T $model_temperature -b $number_of_batches_and_files_to_generate -s $full_model_path_and_file_name -g $greedy_ratio $generation_control_seed $extra_flags\n",
        "\n",
        "print('Successfully exported the output to output-000.mid')\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download('/content/Performance-RNN-PyTorch/output/output-000.mid')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czxhLgcUzBWt",
        "cellView": "form"
      },
      "source": [
        "#@title Plot and Graph the Output :) Only first batch MIDI file is plotted and displayed \n",
        "graphs_length_inches = 18 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "notes_graph_height = 6 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "highest_displayed_pitch = 100 #@param {type:\"slider\", min:1, max:128, step:1}\n",
        "lowest_displayed_pitch = 20 #@param {type:\"slider\", min:1, max:128, step:1}\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pretty_midi\n",
        "import pypianoroll\n",
        "from pypianoroll import Multitrack, Track\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('SVG')\n",
        "# For plotting\n",
        "import mir_eval.display\n",
        "import librosa.display\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "midi_data = pretty_midi.PrettyMIDI('/content/Performance-RNN-PyTorch/output/output-000.mid')\n",
        "\n",
        "def plot_piano_roll(pm, start_pitch, end_pitch, fs=100):\n",
        "    # Use librosa's specshow function for displaying the piano roll\n",
        "    librosa.display.specshow(pm.get_piano_roll(fs)[start_pitch:end_pitch],\n",
        "                             hop_length=1, sr=fs, x_axis='time', y_axis='cqt_note',\n",
        "                             fmin=pretty_midi.note_number_to_hz(start_pitch))\n",
        "\n",
        "\n",
        "\n",
        "roll = np.zeros([int(graphs_length_inches), 128])\n",
        "# Plot the output\n",
        "\n",
        "track = Multitrack('/content/Performance-RNN-PyTorch/output/output-000.mid', name='track')\n",
        "plt.figure(figsize=[graphs_length_inches, notes_graph_height])\n",
        "fig, ax = track.plot()\n",
        "fig.set_size_inches(graphs_length_inches, notes_graph_height)\n",
        "plt.figure(figsize=[graphs_length_inches, notes_graph_height])\n",
        "ax2 = plot_piano_roll(midi_data, lowest_displayed_pitch, highest_displayed_pitch)\n",
        "plt.show(block=False)\n",
        "\n",
        "# Generate rendering (WAV)\n",
        "\n",
        "\n",
        "#audio = midi_data.Synthesize()\n",
        "\n",
        "#print(audio.shape)\n",
        "\n",
        "#plt.figure(figsize=[graphs_length_inches, rendered_wav_graph_height])\n",
        "#plt.plot(audio)\n",
        "#plt.show(block=False)\n",
        "\n",
        "#import IPython.display as ipd\n",
        "#ipd.Audio(audio, rate=16000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHjK-8mm0Si6",
        "cellView": "form"
      },
      "source": [
        "#@title Render first MIDI output file for playback (very slow on long compositions)\n",
        "FluidSynth(\"/content/font.sf2\", sample_rate=16000).midi_to_audio('/content/Performance-RNN-PyTorch/output/output-000.mid','output_wav.wav')\n",
        "\n",
        "# set the src and play\n",
        "Audio(\"output_wav.wav\", rate=16000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqvVYDWFcYPN"
      },
      "source": [
        "###BONUS: Super Plots and Graphs of the Generated Output (Enjoy :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMG8-s2zSgZ9",
        "cellView": "form"
      },
      "source": [
        "#@title Music21 Graphs\n",
        "import music21\n",
        "from music21 import *\n",
        "\n",
        "s = converter.parse(\"/content/Performance-RNN-PyTorch/output/output-000.mid\")\n",
        "\n",
        "p = music21.graph.plot.HistogramPitchSpace(s)\n",
        "p.id\n",
        "'histogram-pitchSpace-count'\n",
        "p.run()  # with defaults and proper configuration, will open graph\n",
        "\n",
        "p = graph.plot.HistogramPitchClass(s)\n",
        "p.id\n",
        "'histogram-pitchClass-count'\n",
        "p.run()\n",
        "\n",
        "p = graph.plot.WindowedKey(s.parts[0])\n",
        "p.run() \n",
        "p = graph.plot.ScatterPitchSpaceQuarterLength(s)\n",
        "p.id\n",
        "'scatter-quarterLength-pitchSpace'\n",
        "p.run()\n",
        "\n",
        "p = graph.plot.Plot3DBarsPitchSpaceQuarterLength(s)\n",
        "p.id\n",
        "'3DBars-quarterLength-pitchSpace-count'\n",
        "p.run()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}